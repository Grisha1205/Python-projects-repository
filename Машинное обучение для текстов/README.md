# Классификация токсичных комментариев

## Содержание
1. [Описание проекта](#описание-проекта)
2. [Цель исследования](#цель-исследования)
3. [Критерии исследования](#критерии-исследования)
4. [Исходные данные](#исходные-данные)
5. [Результаты](#результаты)
6. [Рекомендации](#рекомендации)

## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис, позволяющий пользователям редактировать и дополнять описания товаров. Для поддержания качества контента и комфортной атмосферы необходимо автоматически выявлять токсичные комментарии и отправлять их на модерацию.

## Цель исследования

Обучить модель машинного обучения, способную классифицировать комментарии на позитивные и негативные (токсичные). Модель должна автоматически фильтровать нежелательный контент для последующей проверки модераторами.

## Критерии исследования
- Основная метрика качества — **F1-score**
- Целевое значение метрики: **не менее 0.75**
- Модель должна выдавать вероятности принадлежности к классу «токсичный» для гибкой настройки порога классификации

## Исходные данные

Данные для обучения находятся в файле:
- `/datasets/toxic_comments.csv`

Структура данных:
- `text` — текст комментария
- `toxic` — целевой признак (0 — нетоксичный, 1 — токсичный)

## Результаты

**1. Анализ и предобработка данных:**
- Объем dataset: 159 292 комментария
- Пропуски и дубликаты отсутствуют
- Обнаружен значительный **дисбаланс классов**: большинство комментариев нетоксичны

**2. Обучение и выбор модели:**
- Протестированы модели `LogisticRegression` и `PassiveAggressiveClassifier`
- Наилучший результат показала модель **`PassiveAggressiveClassifier`**

**3. Финальная оценка модели:**
- Максимальное значение метрики **F1 = 0.7755** достигнуто при пороге классификации **0.311**
- При данном пороге:
  - **Recall (полнота)**: 0.73 — модель находит 73% всех токсичных комментариев
  - **Precision (точность)**: 0.83 — 83% комментариев, помеченных моделью как токсичные, действительно являются таковыми

## Рекомендации

1. **Внедрить модель `PassiveAggressiveClassifier`** с порогом срабатывания 0.311 для автоматической модерации

2. **Выбранная стратегия** (высокий Precision) минимизирует нагрузку на модераторов, так как большая часть отправленных на проверку комментариев действительно будет требовать вмешательства

3. **Модель соответствует целям проекта**, так как:
   - Значение F1-score (0.7755) **превышает требуемый порог** в 0.75
   - Обеспечивает баланс между обнаружением токсичных комментариев и точностью срабатывания

Периодически необходимо переобучать модель на новых данных для поддержания ее актуальности и эффективности.
